{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto - Encoder using CNNs\n",
    "\n",
    "## Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model\n",
    "\n",
    "<img src=\"Architecture_cnn.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 3)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.fc1_mu = nn.Linear(12 * 12 * 16, 20)\n",
    "        self.fc1_sig = nn.Linear(12 * 12 * 16, 20)\n",
    "        self.fc2 = nn.Linear(20, 12 * 12 * 16)\n",
    "        self.up_sample = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.conv3 = nn.ConvTranspose2d(16, 32, 3)\n",
    "        self.conv4 = nn.ConvTranspose2d(32, 1, 3)\n",
    "  \n",
    "    def encode(self,x):\n",
    "        a1 = F.relu(self.conv1(x))\n",
    "        a2 = F.relu(self.conv2(a1))\n",
    "        mx_poold = self.max_pool(a2)\n",
    "        a_reshaped = mx_poold.reshape(-1 , 12 * 12 * 16)\n",
    "        a_mu = self.fc1_mu(a_reshaped)\n",
    "        a_logvar = self.fc1_sig(a_reshaped)\n",
    "        return a_mu, a_logvar\n",
    "  \n",
    "    def decode(self,z):\n",
    "        a3 = F.relu(self.fc2(z))\n",
    "        a3 = a3.reshape(-1, 16, 12, 12)\n",
    "        a3_upsample = self.up_sample(a3)\n",
    "        a4 = F.relu(self.conv3(a3_upsample))\n",
    "        a5 = torch.sigmoid(self.conv4(a4))\n",
    "        return a5\n",
    "  \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "  \n",
    "    def forward(self,x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data',train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',train=False, transform=transforms.ToTensor(),download = True)\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,  batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashutoshchaubey/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:177: UserWarning: nn.UpsamplingNearest2d is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.UpsamplingNearest2d is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/Users/ashutoshchaubey/anaconda3/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/Users/ashutoshchaubey/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([100, 784])) that is different to the input size (torch.Size([100, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 , Minibatch : 0 Loss = 54326.6719\n",
      "Epoch : 1 , Minibatch : 100 Loss = 2963207.3535\n",
      "Epoch : 1 , Minibatch : 200 Loss = 1878940.3311\n",
      "Epoch : 1 , Minibatch : 300 Loss = 1469711.3965\n",
      "Epoch : 1 , Minibatch : 400 Loss = 1313537.5762\n",
      "Epoch : 1 , Minibatch : 500 Loss = 1249602.0713\n",
      "Epoch 1 : Loss = (10128098.4697) \n",
      "Epoch : 2 , Minibatch : 0 Loss = 12200.3232\n",
      "Epoch : 2 , Minibatch : 100 Loss = 1188733.4014\n",
      "Epoch : 2 , Minibatch : 200 Loss = 1168597.8184\n",
      "Epoch : 2 , Minibatch : 300 Loss = 1164925.1621\n",
      "Epoch : 2 , Minibatch : 400 Loss = 1150479.5059\n",
      "Epoch : 2 , Minibatch : 500 Loss = 1135445.5137\n",
      "Epoch 2 : Loss = (6940009.0449) \n",
      "Epoch : 3 , Minibatch : 0 Loss = 11324.7793\n",
      "Epoch : 3 , Minibatch : 100 Loss = 1120590.1504\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "print_per = 100\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    print_loss = 0\n",
    "    loss_record = []\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(images)\n",
    "        loss = loss_function(recon_batch, images, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        print_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if (i%print_per == 0):\n",
    "            print(\"Epoch : {} , Minibatch : {} Loss = {:.4f}\".format(epoch+1, i, print_loss))\n",
    "            loss_record.append(print_loss)\n",
    "            print_loss = 0\n",
    "    print(\"Epoch {} : Loss = ({:.4f}) \".format(epoch+1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model(images)[0].data[0].numpy().shape)\n",
    "image1 = images[8].reshape(1, 1, 28, 28)\n",
    "print(image1.shape)\n",
    "plt.imshow(model(images)[0].data[8].numpy().reshape(28, 28), cmap='gray')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "print_per = 10\n",
    "with torch.no_grad():\n",
    "    for i, (images, _) in enumerate(test_loader):\n",
    "        recon_batch, mu, logvar = model(images)\n",
    "        test_loss += loss_function(recon_batch, images, mu, logvar).item()\n",
    "        if (i%print_per == 0):\n",
    "            plt.imshow(model(images)[0].data[0].numpy().reshape(28, 28), cmap='gray')\n",
    "            plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = images[1].reshape(1, 1, 28, 28)\n",
    "print(image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model(images)[0].data[1].numpy().reshape(28, 28), cmap='gray')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1].numpy().reshape(28, 28), cmap='gray')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "All of these are similar to those given in this [notebook](https://github.com/ac-alpha/VAEs-using-Pytorch/blob/master/VAE.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mu1, logvar1 = model.encode(image1)\n",
    "    std1 = torch.exp(0.5*logvar1)\n",
    "    mu2, logvar2 = model.encode(image2)\n",
    "    std2 = torch.exp(0.5*logvar2)\n",
    "    print(mu1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    recon_images1 = []\n",
    "    for ctr in range(0, 100, 5):\n",
    "        eps_val = torch.full_like(mu1, fill_value = ctr * 0.01 )\n",
    "        z_val1 = eps_val.mul(std1).add_(mu1)\n",
    "        recon_image1 = model.decode(z_val1)\n",
    "        recon_images1.append(recon_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recon_images1[0] - recon_images1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(28, 28))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = recon_images1[i-1].detach().numpy().reshape(28, 28)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    recon_images1 = []\n",
    "    eps_val = torch.randn_like(mu1)\n",
    "    for ctr in range(0, 100, 5):\n",
    "        eps_val[:, 7] = ctr * 0.05 * std1[:, 7] + mu1[:, 7]\n",
    "        z_val1 = eps_val.mul(std1).add_(mu1)\n",
    "        recon_image1 = model.decode(z_val1)\n",
    "        recon_images1.append(recon_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(28, 28))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = recon_images1[i-1].detach().numpy().reshape(28, 28)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img, cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_any = torch.randn_like(mu1)\n",
    "z1 = eps_any.mul(std1).add_(mu1)\n",
    "z2 = eps_any.mul(std2).add_(mu2)\n",
    "all_recons = []\n",
    "for i in range(20):\n",
    "    z_bet = z1 + torch.full_like(mu1, fill_value = 0.05*i).mul(z2 - z1)\n",
    "    recon_image = model.decode(z_bet)\n",
    "    all_recons.append(recon_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(28, 28))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = all_recons[i-1].detach().numpy().reshape(28, 28)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
